{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os, sys\n",
    "import json\n",
    "import time\n",
    "import skimage.io\n",
    "import configparser\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSectionToUse(config_dict):\n",
    "    ini_section = 'DEFAULT'\n",
    "    if config_dict.has_option('DEFAULT', 'section_to_use'):\n",
    "        if config_dict['DEFAULT']['section_to_use'] != '':\n",
    "            ini_section = config_dict['DEFAULT']['section_to_use']\n",
    "            if ini_section not in config_dict.sections():\n",
    "                raise ValueError('section_to_use  ' + ini_section + ' stated in env.ini is not a valid section.')\n",
    "    else:\n",
    "        print('Section_to_use not specified in env.ini. Using Default values.')\n",
    "    return ini_section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = configparser.ConfigParser()\n",
    "config_dict.read('env.ini')\n",
    "ini_section = getSectionToUse(config_dict)\n",
    "RCNN_DIR = config_dict[ini_section]['RCNN_DIR']\n",
    "if not os.path.isdir(RCNN_DIR):\n",
    "    raise NotADirectoryError(RCNN_DIR + \" in env.ini is not a directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# SET UP RCNN LOGS AND COCO DEPENDENCIES \n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(RCNN_DIR, \"logs\")\n",
    "print('Creating model')\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(RCNN_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "    \n",
    "sys.path.append(os.path.abspath(RCNN_DIR))\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "# Import COCO config\n",
    "sys.path.append(os.path.join(RCNN_DIR, \"samples/coco/\"))  # To find local version\n",
    "import coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectColour(image, aoi, threshold=0.3 ):\n",
    "    # define the list of boundaries\n",
    "    boundaries = [ #RGB\n",
    "        ([100, 50, 50], [255, 130, 130], 'RED'),\n",
    "        ([50, 100, 50], [130, 255, 130], 'GREEN'),\n",
    "        ([50, 50, 100], [130, 130, 255], 'BLUE'),\n",
    "        ([100, 100, 50], [255, 255, 130], 'YELLOW' ),\n",
    "        ([100, 100, 100], [225, 225, 225], 'SILVER' ), \n",
    "        ([225, 225, 225], [255, 255, 255], 'WHITE' ),\n",
    "        ([0, 0, 0], [100, 100, 100], 'BLACK' ) \n",
    "    ]\n",
    "    # loop over the boundaries\n",
    "    for (lower, upper, colour) in boundaries:\n",
    "    # (lower, upper, colour) = boundaries[4]\n",
    "        # create NumPy arrays from the boundaries\n",
    "        lower = np.array(lower, dtype = \"uint8\")\n",
    "        upper = np.array(upper, dtype = \"uint8\")\n",
    "\n",
    "        # find the colors within the specified boundaries and apply\n",
    "        # the mask\n",
    "        mask = cv2.inRange(image, lower, upper)\n",
    "\n",
    "        tmp_mask = np.logical_and(mask, aoi)\n",
    "        output = cv2.bitwise_and(image, image, mask = tmp_mask.astype(\"uint8\"))\n",
    "        # print(np.sum(np.logical_and(mask, aoi))/np.sum(aoi))\n",
    "        isColour = np.sum(np.logical_and(mask, aoi))/np.sum(aoi) > threshold\n",
    "        if isColour:\n",
    "            return colour, output\n",
    "            \n",
    "    return \"OTHERS\", output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImageIdfrmPath(path, case='oneMotoring'):\n",
    "    image_id = ''\n",
    "    # for onemotoring:\n",
    "    if case.lower() == 'oneMotoring'.lower():\n",
    "        path, im = os.path.split(path)\n",
    "        path, date = os.path.split(path)\n",
    "        path, location = os.path.split(path)\n",
    "        image_id = location.replace(' ', '_') + '-' + date + '-' + im.replace('.jpeg','')\n",
    "    return image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeVariables(config_dict):\n",
    "    ini_section = getSectionToUse(config_dict)\n",
    "    # Initialise of output<dict> with items in reference.json\n",
    "    F_ref = open(config_dict[ini_section]['reference_file'],'r')  # TODO: add error checks\n",
    "    text_ = F_ref.read()\n",
    "    json_ref = json.loads(text_)\n",
    "    jsonOutput = {'categories': json_ref['categories'], \\\n",
    "                 'annotations': [], \\\n",
    "                 'images': json_ref['images'], \\\n",
    "                 'licenses': json_ref['licenses']}\n",
    "    F_ref.close()\n",
    "    \n",
    "    if not config_dict.has_option(ini_section, 'obj_of_interest'):\n",
    "        raise ValueError('Object of interest not found in env.ini')\n",
    "    \n",
    "    if not config_dict.has_option(ini_section, 'im_dir'):\n",
    "        raise ValueError('Image directory not found in env.ini')\n",
    "        \n",
    "    if not config_dict.has_option(ini_section, 'output_file'):\n",
    "        raise ValueError('Output_file path not found in env.ini')\n",
    "    \n",
    "    if not config_dict.has_option(ini_section, 'batch_size'):\n",
    "        raise ValueError('batch_size not found in env.ini')\n",
    "    \n",
    "    if not config_dict.has_option(ini_section, 'threshold'):\n",
    "        raise ValueError('Min. size for object detection, threshold, not found in env.ini')\n",
    "        \n",
    "    if not config_dict.has_option(ini_section, 'ann_id_prefix'):\n",
    "        raise ValueError('Annotation id prefix, ann_id_prefix not found in env.ini')\n",
    "    return jsonOutput, config_dict[ini_section]\n",
    "\n",
    "def get_lines_as_list(file_path):\n",
    "    File = open(file_path, 'r')\n",
    "    lines = File.readlines()\n",
    "    lines_in_list = [x.strip() for x in lines] \n",
    "    File.close()\n",
    "    return lines_in_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALISATION OF VARIABLES\n",
    "jsonOutput, config_ = initializeVariables(config_dict)  # use config with underscore to prevent conflict with pyco's config\n",
    "OBJECTS_OF_INTEREST_ls = config_['obj_of_interest']\n",
    "IM_DIR = config_['im_dir']\n",
    "output_file = config_['output_file']\n",
    "BATCH_SIZE = int(config_['batch_size'])\n",
    "THRESHOLD = float(config_['threshold'])\n",
    "ANN_ID_PREFIX = config_['ann_id_prefix']\n",
    "OBJECTS_OF_INTEREST_ls = [ int(x) for x in OBJECTS_OF_INTEREST_ls.replace('[','').replace(']','').split(',')]\n",
    "done_list_path = config_['done_list']\n",
    "'BUS' in ', '.join([items['id'] for items in jsonOutput['categories']]).split(', ')\n",
    "ann_json_list = []\n",
    "if len(done_list_path) != 0:\n",
    "    done_list = get_lines_as_list(done_list_path)\n",
    "else:\n",
    "    done_list = []\n",
    "global_counter = 1\n",
    "other_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bicycle\n",
      "train\n",
      "traffic light\n",
      "stop sign\n",
      "Removing bicycle from objects-of-interest list as it is not present in the category list of reference.json\n",
      "Removing train from objects-of-interest list as it is not present in the category list of reference.json\n",
      "Removing traffic light from objects-of-interest list as it is not present in the category list of reference.json\n",
      "Removing stop sign from objects-of-interest list as it is not present in the category list of reference.json\n"
     ]
    }
   ],
   "source": [
    "# COCO Class names\n",
    "# Index of the class in the list is its ID. For example, to get ID of\n",
    "# the teddy bear class, use: class_names.index('teddy bear')\n",
    "# class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "#                'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "#                'fire hydrant', 'stop sign']\n",
    "\n",
    "# OVERRIDES MASK_RCNN DEFAULTS\n",
    "class_names = ['BG', 'person', 'bicycle', 'SEDAN', 'motorcycle', 'airplane',\n",
    "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "               'fire hydrant', 'stop sign']\n",
    "\n",
    "# REMOVES OBJECTS THAT ARE OF INTEREST BUT ARE NOT IN REFERENCE CATEGORY LIST\n",
    "categories_list = ', '.join([items['id'] for items in jsonOutput['categories']]).lower().split(', ')\n",
    "ref_indices_to_be_removed = []\n",
    "for obj_ref_idx in OBJECTS_OF_INTEREST_ls:\n",
    "    if not class_names[obj_ref_idx].lower() in categories_list:\n",
    "        ref_indices_to_be_removed.append(obj_ref_idx)\n",
    "        print(class_names[obj_ref_idx])\n",
    "for i in ref_indices_to_be_removed:\n",
    "    print('Removing ' + class_names[i] + ' from objects-of-interest list as it is not present in the category list of reference.json')\n",
    "    OBJECTS_OF_INTEREST_ls.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     5\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 5\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                93\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(RCNN_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(RCNN_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "\n",
    "class InferenceConfig(coco.CocoConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = BATCH_SIZE\n",
    "\n",
    "inf_config = InferenceConfig()\n",
    "inf_config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Xin Yan\\Anaconda3\\envs\\shapEnv\\lib\\site-packages\\tensorflow\\python\\ops\\sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "Found 8319 images.\n",
      "Nothing detected in image with id: AYE_-_View_from_After_Tuas_West_Road-20190114-20190114T224619.458\n",
      "Nothing detected in image with id: AYE_-_View_from_After_Tuas_West_Road-20190114-20190114T230117.114\n",
      "Nothing detected in image with id: AYE_-_View_from_After_Tuas_West_Road-20190114-20190114T232116.988\n",
      "Nothing detected in image with id: AYE_-_View_from_After_Tuas_West_Road-20190114-20190114T232617.176\n",
      "Nothing detected in image with id: AYE_-_View_from_After_Tuas_West_Road-20190115-20190115T090913.858\n",
      "Nothing detected in image with id: AYE_-_View_from_After_Tuas_West_Road-20190115-20190115T100912.817\n",
      "Nothing detected in image with id: AYE_-_View_from_After_Tuas_West_Road-20190116-20190116T122350.458\n",
      "Nothing detected in image with id: AYE_-_View_from_After_Tuas_West_Road-20190116-20190116T122850.147\n",
      "Nothing detected in image with id: AYE_-_View_from_After_Tuas_West_Road-20190117-20190117T071302.188\n",
      "Nothing detected in image with id: AYE_-_View_from_After_Tuas_West_Road-20190117-20190117T143517.664\n",
      "Nothing detected in image with id: AYE_-_View_from_After_Tuas_West_Road-20190117-20190117T162808.399\n",
      "100 image(s) done. 8219 more to go. Hang in there!\n",
      "Nothing detected in image with id: AYE_-_View_from_Clementi_Ave_6_Entrance-20190117-20190117T071302.347\n",
      "Nothing detected in image with id: AYE_-_View_from_Clementi_Ave_6_Entrance-20190117-20190117T143517.753\n",
      "Nothing detected in image with id: AYE_-_View_from_Clementi_Ave_6_Entrance-20190117-20190117T162808.665\n",
      "200 image(s) done. 8119 more to go. Hang in there!\n",
      "Nothing detected in image with id: AYE_-_View_from_Entrance_from_Benoi_Rd-20190114-20190114T224619.786\n",
      "Nothing detected in image with id: AYE_-_View_from_Entrance_from_Benoi_Rd-20190114-20190114T225120.317\n",
      "Nothing detected in image with id: AYE_-_View_from_Entrance_from_Benoi_Rd-20190114-20190114T230117.363\n",
      "Nothing detected in image with id: AYE_-_View_from_Entrance_from_Benoi_Rd-20190116-20190116T130351.249\n",
      "Nothing detected in image with id: AYE_-_View_from_Entrance_from_Benoi_Rd-20190117-20190117T071302.454\n",
      "Nothing detected in image with id: AYE_-_View_from_Entrance_from_Benoi_Rd-20190117-20190117T143517.860\n",
      "Nothing detected in image with id: AYE_-_View_from_Entrance_from_Benoi_Rd-20190117-20190117T162808.913\n",
      "Nothing detected in image with id: AYE_-_View_from_Entrance_from_Jln_Ahmad_Ibrahim-20190114-20190114T161059.740\n",
      "Nothing detected in image with id: AYE_-_View_from_Entrance_from_Jln_Ahmad_Ibrahim-20190114-20190114T221117.614\n",
      "Nothing detected in image with id: AYE_-_View_from_Entrance_from_Jln_Ahmad_Ibrahim-20190114-20190114T223117.034\n",
      "300 image(s) done. 8019 more to go. Hang in there!\n",
      "Nothing detected in image with id: AYE_-_View_from_Entrance_from_Jln_Ahmad_Ibrahim-20190114-20190114T231117.020\n",
      "Nothing detected in image with id: AYE_-_View_from_Entrance_from_Jln_Ahmad_Ibrahim-20190114-20190114T233117.284\n",
      "Nothing detected in image with id: AYE_-_View_from_Entrance_from_Jln_Ahmad_Ibrahim-20190115-20190115T092912.626\n",
      "Nothing detected in image with id: AYE_-_View_from_Entrance_from_Jln_Ahmad_Ibrahim-20190116-20190116T122850.584\n",
      "Nothing detected in image with id: AYE_-_View_from_Entrance_from_Jln_Ahmad_Ibrahim-20190116-20190116T123351.211\n",
      "Nothing detected in image with id: AYE_-_View_from_Entrance_from_Jln_Ahmad_Ibrahim-20190117-20190117T071302.585\n",
      "Nothing detected in image with id: AYE_-_View_from_Entrance_from_Jln_Ahmad_Ibrahim-20190117-20190117T143517.968\n",
      "Nothing detected in image with id: AYE_-_View_from_Entrance_from_Jln_Ahmad_Ibrahim-20190117-20190117T162809.164\n",
      "400 image(s) done. 7919 more to go. Hang in there!\n",
      "Nothing detected in image with id: AYE_-_View_from_Entrance_from_Yuan_Ching_Rd-20190117-20190117T071302.673\n",
      "Nothing detected in image with id: AYE_-_View_from_Entrance_from_Yuan_Ching_Rd-20190117-20190117T143518.171\n",
      "Nothing detected in image with id: AYE_-_View_from_Entrance_from_Yuan_Ching_Rd-20190117-20190117T162809.397\n",
      "Nothing detected in image with id: AYE_-_View_from_Keppel_Viaduct-20190117-20190117T071302.787\n",
      "Nothing detected in image with id: AYE_-_View_from_Keppel_Viaduct-20190117-20190117T143518.283\n",
      "500 image(s) done. 7819 more to go. Hang in there!\n",
      "Nothing detected in image with id: AYE_-_View_from_Lower_Delta_Road-20190117-20190117T071302.876\n",
      "Nothing detected in image with id: AYE_-_View_from_Lower_Delta_Road-20190117-20190117T143518.424\n",
      "Nothing detected in image with id: AYE_-_View_from_Lower_Delta_Road-20190117-20190117T162809.945\n",
      "600 image(s) done. 7719 more to go. Hang in there!\n",
      "Nothing detected in image with id: AYE_-_View_from_Near_Dover_Drive-20190117-20190117T071303.049\n",
      "Nothing detected in image with id: AYE_-_View_from_Near_Dover_Drive-20190117-20190117T143518.516\n",
      "Nothing detected in image with id: AYE_-_View_from_Near_Dover_Drive-20190117-20190117T162810.209\n",
      "700 image(s) done. 7619 more to go. Hang in there!\n",
      "Nothing detected in image with id: AYE_-_View_from_Near_NUS-20190117-20190117T071303.142\n",
      "Nothing detected in image with id: AYE_-_View_from_Near_NUS-20190117-20190117T143518.609\n",
      "Nothing detected in image with id: AYE_-_View_from_Near_NUS-20190117-20190117T162810.529\n",
      "800 image(s) done. 7519 more to go. Hang in there!\n",
      "900 image(s) done. 7419 more to go. Hang in there!\n",
      "Nothing detected in image with id: AYE_-_View_from_Towards_Alexandra_Road-20190117-20190117T071303.407\n",
      "Nothing detected in image with id: AYE_-_View_from_Towards_Alexandra_Road-20190117-20190117T143518.861\n",
      "Nothing detected in image with id: AYE_-_View_from_Towards_Alexandra_Road-20190117-20190117T162811.116\n",
      "Nothing detected in image with id: AYE_-_View_from_Towards_Pandan_Gardens-20190114-20190114T230618.552\n",
      "1000 image(s) done. 7319 more to go. Hang in there!\n",
      "Nothing detected in image with id: BKE_-_View_from_Chantek_Flyover-20190110-20190110T083322.779\n",
      "Nothing detected in image with id: BKE_-_View_from_Chantek_Flyover-20190110-20190110T083823.086\n",
      "Nothing detected in image with id: BKE_-_View_from_Chantek_Flyover-20190110-20190110T084322.955\n",
      "Nothing detected in image with id: BKE_-_View_from_Chantek_Flyover-20190110-20190110T084822.828\n",
      "Nothing detected in image with id: BKE_-_View_from_Chantek_Flyover-20190110-20190110T085322.382\n",
      "Nothing detected in image with id: BKE_-_View_from_Chantek_Flyover-20190110-20190110T085822.878\n",
      "Nothing detected in image with id: BKE_-_View_from_Chantek_Flyover-20190110-20190110T090323.524\n",
      "1100 image(s) done. 7219 more to go. Hang in there!\n",
      "Nothing detected in image with id: BKE_-_View_from_Chantek_Flyover-20190110-20190110T090822.885\n",
      "Nothing detected in image with id: BKE_-_View_from_Chantek_Flyover-20190110-20190110T091323.058\n",
      "Nothing detected in image with id: BKE_-_View_from_Chantek_Flyover-20190110-20190110T092022.623\n",
      "Nothing detected in image with id: BKE_-_View_from_Chantek_Flyover-20190110-20190110T092322.730\n",
      "Nothing detected in image with id: BKE_-_View_from_Chantek_Flyover-20190110-20190110T092822.199\n",
      "Nothing detected in image with id: BKE_-_View_from_Chantek_Flyover-20190110-20190110T093322.608\n",
      "1200 image(s) done. 7119 more to go. Hang in there!\n",
      "Nothing detected in image with id: BKE_-_View_from_Dairy_Farm_Flyover-20190114-20190114T231619.037\n",
      "1300 image(s) done. 7019 more to go. Hang in there!\n"
     ]
    }
   ],
   "source": [
    "# MAIN\n",
    "# Create model object in inference mode.\n",
    "DEVICE = \"/gpu:0\"  # /cpu:0 or /gpu:0\n",
    "with tf.device(DEVICE):\n",
    "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=inf_config)\n",
    "\n",
    "    # Load weights trained on MS-COCO\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True)\n",
    "\n",
    "    # MAIN\n",
    "    # TODO track done images and images with objects not of interest\n",
    "    list_of_image_paths = []\n",
    "    for path, subdirs, files in os.walk(IM_DIR):\n",
    "        for file in files:\n",
    "            if file.endswith('.jpeg'):\n",
    "                list_of_image_paths.append(os.path.join(path, file))\n",
    "\n",
    "    print('Found ' + str(len(list_of_image_paths)) + ' images.')\n",
    "    im_generator = enumerate(list_of_image_paths)\n",
    "    global_counter = 0\n",
    "    end_of_list = False\n",
    "    start = time.time() \n",
    "    if (len(list_of_image_paths)==0):\n",
    "        print('No images was found in ')\n",
    "\n",
    "    while not end_of_list:\n",
    "        image_array = []\n",
    "        image_sz_array = []\n",
    "        image_path_array = []\n",
    "        for i in range(BATCH_SIZE):\n",
    "            try: im_counter, nxt_im_path = im_generator.__next__()\n",
    "            except StopIteration: end_of_list = True; break\n",
    "            image = skimage.io.imread(nxt_im_path)\n",
    "            image_array.append(image)\n",
    "            image_sz_array.append(image.shape)  # height, width, _ \n",
    "            image_path_array.append(nxt_im_path)\n",
    "\n",
    "        if len(image_array) == BATCH_SIZE:\n",
    "            test_results = model.detect(image_array, verbose=0)\n",
    "        else:\n",
    "            # initialise a model with the corresponding BATCH_SIZE\n",
    "            config_new_config = InferenceConfig()\n",
    "            config_new_config.BATCH_SIZE = len(image_array)\n",
    "            config_new_config.IMAGES_PER_GPU = len(image_array)\n",
    "            config_new_config.NAME = \"coco_odd_size\"\n",
    "            config_new_config.display()\n",
    "            # Create model object in inference mode.\n",
    "            model_odd_batch_size = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config_new_config)\n",
    "            # Load weights trained on MS-COCO\n",
    "            model_odd_batch_size.load_weights(COCO_MODEL_PATH, by_name=True)\n",
    "            test_results = model_odd_batch_size.detect(image_array, verbose=0)\n",
    "\n",
    "        for ii in range(len(test_results)):\n",
    "            r = test_results[ii]\n",
    "            image_id = getImageIdfrmPath(image_path_array[ii])\n",
    "            height, width, _ = image_sz_array[ii]\n",
    "            for idx, roi in enumerate(r['rois']):\n",
    "                if len(OBJECTS_OF_INTEREST_ls) != 0 and r['class_ids'][idx] not in OBJECTS_OF_INTEREST_ls:\n",
    "                    other_list.append({'category_id': idx, \"image_id\": image_id})\n",
    "                    continue\n",
    "                y1, x1, y2, x2 = roi\n",
    "                aoi = r['masks'][y1:y2, x1:x2,idx]\n",
    "                input = image_array[ii][y1:y2, x1:x2]\n",
    "                colour, _ = detectColour(input, aoi)\n",
    "\n",
    "                bbox = [float(x1)/width, float(y1)/height, float(x2-x1)/width, float(y2-y1)/height]  # Normalise for annotation tool\n",
    "                if ((bbox[2]<THRESHOLD) or (bbox[3]<THRESHOLD)):\n",
    "                    continue\n",
    "                cat_id = class_names[r['class_ids'][idx]].upper()\n",
    "\n",
    "                if cat_id != 'MOTORCYCLE':\n",
    "                    ann = {\"id\" : ANN_ID_PREFIX+str(global_counter), \"image_id\": image_id, 'category_id': cat_id +\", \"+colour, 'bbox': bbox}\n",
    "                else:\n",
    "                    ann = {\"id\" : ANN_ID_PREFIX+str(global_counter), \"image_id\": image_id, 'category_id': cat_id, 'bbox': bbox}\n",
    "\n",
    "                global_counter+=1\n",
    "                ann_json_list.append(ann)\n",
    "            if len(r['rois'])==0:\n",
    "                print('Nothing detected in image with id: '+ image_id)\n",
    "\n",
    "\n",
    "        if ((im_counter != 0) and ((im_counter+1) % 100)==0):\n",
    "            print(str(im_counter+1) + ' image(s) done. ' + str(len(list_of_image_paths)-im_counter-1) + ' more to go. Hang in there!')\n",
    "            with open(output_file.replace('.json','_done_list_' + str(im_counter+1) + '.txt'), 'w') as f:\n",
    "                for item in list_of_image_paths:\n",
    "                    f.write(\"%s\\n\" % item)\n",
    "\n",
    "            if len(ann_json_list)==0:\n",
    "                print('Nothing detected yet.')\n",
    "            else:\n",
    "                jsonOutput['annotations'] = ann_json_list\n",
    "                File = open(output_file.replace('.json', '_'+ str(im_counter) + '.json'),'w')\n",
    "                File.write(json.dumps(jsonOutput))\n",
    "                File.close()\n",
    "    end = time.time()\n",
    "    print(end - start)\n",
    "\n",
    "    if len(ann_json_list)==0:\n",
    "        print('Nothing detected.')\n",
    "    else:\n",
    "        jsonOutput['annotations'] = ann_json_list\n",
    "        File = open(output_file,'w')\n",
    "        File.write(json.dumps(jsonOutput))\n",
    "        File.close()\n",
    "\n",
    "\n",
    "    with open(output_file.replace('.json','_done_list.txt'), 'w') as f:\n",
    "        for item in list_of_image_paths:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "    if (len(other_list) != 0):\n",
    "        File = open(output_file.replace('.json','_strange_list.json'),'w')\n",
    "        File.write(json.dumps({'strange objects': other_list}))\n",
    "        File.close()\n",
    "\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (shapEnv)",
   "language": "python",
   "name": "shapenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
