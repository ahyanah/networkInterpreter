{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os, sys\n",
    "import json\n",
    "import time\n",
    "import skimage.io\n",
    "import configparser\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "def getSectionToUse(config_dict):\n",
    "    ini_section = 'DEFAULT'\n",
    "    if config_dict.has_option('DEFAULT', 'section_to_use'):\n",
    "        if config_dict['DEFAULT']['section_to_use'] != '':\n",
    "            ini_section = config_dict['DEFAULT']['section_to_use']\n",
    "            if ini_section not in config_dict.sections():\n",
    "                raise ValueError('section_to_use  ' + ini_section + ' stated in env.ini is not a valid section.')\n",
    "    else:\n",
    "        print('Section_to_use not specified in env.ini. Using Default values.')\n",
    "    return ini_section\n",
    "\n",
    "config_dict = configparser.ConfigParser()\n",
    "config_dict.read('env.ini')\n",
    "ini_section = getSectionToUse(config_dict)\n",
    "RCNN_DIR = config_dict[ini_section]['RCNN_DIR']\n",
    "if not os.path.isdir(RCNN_DIR):\n",
    "    raise NotADirectoryError(RCNN_DIR + \" in env.ini is not a directory.\")\n",
    "\n",
    "\n",
    "# SET UP RCNN LOGS AND COCO DEPENDENCIES \n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(RCNN_DIR, \"logs\")\n",
    "print('Creating model')\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(RCNN_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "    \n",
    "sys.path.append(os.path.abspath(RCNN_DIR))\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "# Import COCO config\n",
    "sys.path.append(os.path.join(RCNN_DIR, \"samples/coco/\"))  # To find local version\n",
    "import coco\n",
    "\n",
    "def detectColour(image, aoi, threshold=0.3 ):\n",
    "    # define the list of boundaries\n",
    "    boundaries = [ #RGB\n",
    "        ([100, 50, 50], [255, 130, 130], 'RED'),\n",
    "        ([50, 100, 50], [130, 255, 130], 'GREEN'),\n",
    "        ([50, 50, 100], [130, 130, 255], 'BLUE'),\n",
    "        ([100, 100, 50], [255, 255, 130], 'YELLOW' ),\n",
    "        ([100, 100, 100], [225, 225, 225], 'SILVER' ), \n",
    "        ([225, 225, 225], [255, 255, 255], 'WHITE' ),\n",
    "        ([0, 0, 0], [100, 100, 100], 'BLACK' ) \n",
    "    ]\n",
    "    # loop over the boundaries\n",
    "    for (lower, upper, colour) in boundaries:\n",
    "    # (lower, upper, colour) = boundaries[4]\n",
    "        # create NumPy arrays from the boundaries\n",
    "        lower = np.array(lower, dtype = \"uint8\")\n",
    "        upper = np.array(upper, dtype = \"uint8\")\n",
    "\n",
    "        # find the colors within the specified boundaries and apply\n",
    "        # the mask\n",
    "        mask = cv2.inRange(image, lower, upper)\n",
    "\n",
    "        tmp_mask = np.logical_and(mask, aoi)\n",
    "        output = cv2.bitwise_and(image, image, mask = tmp_mask.astype(\"uint8\"))\n",
    "        # print(np.sum(np.logical_and(mask, aoi))/np.sum(aoi))\n",
    "        isColour = np.sum(np.logical_and(mask, aoi))/np.sum(aoi) > threshold\n",
    "        if isColour:\n",
    "            return colour, output\n",
    "            \n",
    "    return \"OTHERS\", output\n",
    "\n",
    "def getImageIdfrmPath(path, case='oneMotoring'):\n",
    "    image_id = ''\n",
    "    # for onemotoring:\n",
    "    if case.lower() == 'oneMotoring'.lower():\n",
    "        path, im = os.path.split(path)\n",
    "        path, date = os.path.split(path)\n",
    "        path, location = os.path.split(path)\n",
    "        image_id = location.replace(' ', '_') + '-' + date + '-' + im.replace('.jpeg','')\n",
    "    return image_id\n",
    "\n",
    "\n",
    "def initializeVariables(config_dict):\n",
    "    ini_section = getSectionToUse(config_dict)\n",
    "    # Initialise of output<dict> with items in reference.json\n",
    "    F_ref = open(config_dict[ini_section]['reference_file'],'r')  # TODO: add error checks\n",
    "    text_ = F_ref.read()\n",
    "    json_ref = json.loads(text_)\n",
    "    jsonOutput = {'categories': json_ref['categories'],                  'annotations': [],                  'images': json_ref['images'],                  'licenses': json_ref['licenses']}\n",
    "    F_ref.close()\n",
    "    \n",
    "    if not config_dict.has_option(ini_section, 'obj_of_interest'):\n",
    "        raise ValueError('Object of interest not found in env.ini')\n",
    "    \n",
    "    if not config_dict.has_option(ini_section, 'im_dir'):\n",
    "        raise ValueError('Image directory not found in env.ini')\n",
    "        \n",
    "    if not config_dict.has_option(ini_section, 'output_file'):\n",
    "        raise ValueError('Output_file path not found in env.ini')\n",
    "    \n",
    "    if not config_dict.has_option(ini_section, 'batch_size'):\n",
    "        raise ValueError('batch_size not found in env.ini')\n",
    "    \n",
    "    if not config_dict.has_option(ini_section, 'threshold'):\n",
    "        raise ValueError('Min. size for object detection, threshold, not found in env.ini')\n",
    "        \n",
    "    if not config_dict.has_option(ini_section, 'ann_id_prefix'):\n",
    "        raise ValueError('Annotation id prefix, ann_id_prefix not found in env.ini')\n",
    "    return jsonOutput, config_dict[ini_section]\n",
    "\n",
    "def get_lines_as_list(file_path):\n",
    "    File = open(file_path, 'r')\n",
    "    lines = File.readlines()\n",
    "    lines_in_list = [x.strip() for x in lines] \n",
    "    File.close()\n",
    "    return lines_in_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing bicycle from objects-of-interest list as it is not present in the category list of reference.json\n",
      "Removing train from objects-of-interest list as it is not present in the category list of reference.json\n",
      "Removing traffic light from objects-of-interest list as it is not present in the category list of reference.json\n",
      "Removing stop sign from objects-of-interest list as it is not present in the category list of reference.json\n",
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     2\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 2\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                93\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# INITIALISATION OF VARIABLES\n",
    "jsonOutput, config_ = initializeVariables(config_dict)  # use config with underscore to prevent conflict with pyco's config\n",
    "OBJECTS_OF_INTEREST_ls = config_['obj_of_interest']\n",
    "IM_DIR = config_['im_dir']\n",
    "output_file = config_['output_file']\n",
    "BATCH_SIZE = int(config_['batch_size'])\n",
    "THRESHOLD = float(config_['threshold'])\n",
    "ANN_ID_PREFIX = config_['ann_id_prefix']\n",
    "OBJECTS_OF_INTEREST_ls = [ int(x) for x in OBJECTS_OF_INTEREST_ls.replace('[','').replace(']','').split(',')]\n",
    "done_list_path = config_['done_list']\n",
    "'BUS' in ', '.join([items['id'] for items in jsonOutput['categories']]).split(', ')\n",
    "ann_json_list = []\n",
    "if len(done_list_path) != 0:\n",
    "    done_list = get_lines_as_list(done_list_path)\n",
    "else:\n",
    "    done_list = []\n",
    "global_counter = 1\n",
    "other_list = []\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "# COCO Class names\n",
    "# Index of the class in the list is its ID. For example, to get ID of\n",
    "# the teddy bear class, use: class_names.index('teddy bear')\n",
    "# class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "#                'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "#                'fire hydrant', 'stop sign']\n",
    "\n",
    "# OVERRIDES MASK_RCNN DEFAULTS\n",
    "class_names = ['BG', 'person', 'bicycle', 'SEDAN', 'motorcycle', 'airplane',\n",
    "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "               'fire hydrant', 'stop sign']\n",
    "\n",
    "# REMOVES OBJECTS THAT ARE OF INTEREST BUT ARE NOT IN REFERENCE CATEGORY LIST\n",
    "categories_list = ', '.join([items['id'] for items in jsonOutput['categories']]).lower().split(', ')\n",
    "ref_indices_to_be_removed = []\n",
    "for obj_ref_idx in OBJECTS_OF_INTEREST_ls:\n",
    "    if not class_names[obj_ref_idx].lower() in categories_list:\n",
    "        ref_indices_to_be_removed.append(obj_ref_idx)\n",
    "for i in ref_indices_to_be_removed:\n",
    "    print('Removing ' + class_names[i] + ' from objects-of-interest list as it is not present in the category list of reference.json')\n",
    "    OBJECTS_OF_INTEREST_ls.remove(i)\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(RCNN_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(RCNN_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "\n",
    "class InferenceConfig(coco.CocoConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = BATCH_SIZE\n",
    "\n",
    "inf_config = InferenceConfig()\n",
    "inf_config.display()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "list_of_image_paths = []\n",
    "assert os.path.isdir(IM_DIR), IM_DIR + \" is an invalid image directory.\"\n",
    "\n",
    "for path, subdirs, files in os.walk(IM_DIR):\n",
    "    for file in files:\n",
    "        if file.endswith('.jpeg'):\n",
    "            list_of_image_paths.append(os.path.join(path, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (shapEnv)",
   "language": "python",
   "name": "shapenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
