{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os, sys\n",
    "import json\n",
    "import time\n",
    "import skimage.io\n",
    "import configparser\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSectionToUse(config_dict):\n",
    "    ini_section = 'DEFAULT'\n",
    "    if config_dict.has_option('DEFAULT', 'section_to_use'):\n",
    "        if config_dict['DEFAULT']['section_to_use'] != '':\n",
    "            ini_section = config_dict['DEFAULT']['section_to_use']\n",
    "            if ini_section not in config_dict.sections():\n",
    "                raise ValueError('section_to_use  ' + ini_section + ' stated in env.ini is not a valid section.')\n",
    "    else:\n",
    "        print('Section_to_use not specified in env.ini. Using Default values.')\n",
    "    return ini_section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = configparser.ConfigParser()\n",
    "config_dict.read('env.ini')\n",
    "ini_section = getSectionToUse(config_dict)\n",
    "RCNN_DIR = config_dict[ini_section]['RCNN_DIR']\n",
    "if not os.path.isdir(RCNN_DIR):\n",
    "    raise NotADirectoryError(RCNN_DIR + \" in env.ini is not a directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# # Root directory of the project\n",
    "# ROOT_DIR = os.path.abspath(\"../\")\n",
    "# Import Mask RCNN\n",
    "# sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "# Import COCO config\n",
    "# sys.path.append(os.path.join(ROOT_DIR, \"samples/coco/\"))  # To find local version\n",
    "# import coco\n",
    "\n",
    "sys.path.append(os.path.abspath(RCNN_DIR))\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "# Import COCO config\n",
    "sys.path.append(os.path.join(RCNN_DIR, \"samples/coco/\"))  # To find local version\n",
    "import coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectColour(image, aoi, threshold=0.3 ):\n",
    "    # define the list of boundaries\n",
    "    boundaries = [ #RGB\n",
    "        ([100, 50, 50], [255, 130, 130], 'RED'),\n",
    "        ([50, 100, 50], [130, 255, 130], 'GREEN'),\n",
    "        ([50, 50, 100], [130, 130, 255], 'BLUE'),\n",
    "        ([100, 100, 50], [255, 255, 130], 'YELLOW' ),\n",
    "        ([100, 100, 100], [225, 225, 225], 'SILVER' ), \n",
    "        ([225, 225, 225], [255, 255, 255], 'WHITE' ),\n",
    "        ([0, 0, 0], [100, 100, 100], 'BLACK' ) \n",
    "    ]\n",
    "    # loop over the boundaries\n",
    "    for (lower, upper, colour) in boundaries:\n",
    "    # (lower, upper, colour) = boundaries[4]\n",
    "        # create NumPy arrays from the boundaries\n",
    "        lower = np.array(lower, dtype = \"uint8\")\n",
    "        upper = np.array(upper, dtype = \"uint8\")\n",
    "\n",
    "        # find the colors within the specified boundaries and apply\n",
    "        # the mask\n",
    "        mask = cv2.inRange(image, lower, upper)\n",
    "\n",
    "        tmp_mask = np.logical_and(mask, aoi)\n",
    "        output = cv2.bitwise_and(image, image, mask = tmp_mask.astype(\"uint8\"))\n",
    "        # print(np.sum(np.logical_and(mask, aoi))/np.sum(aoi))\n",
    "        isColour = np.sum(np.logical_and(mask, aoi))/np.sum(aoi) > threshold\n",
    "        if isColour:\n",
    "            return colour, output\n",
    "            \n",
    "    return \"OTHERS\", output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImageIdfrmPath(path, case='oneMotoring'):\n",
    "    image_id = ''\n",
    "    # for onemotoring:\n",
    "    if case.lower() == 'oneMotoring'.lower():\n",
    "        path, im = os.path.split(path)\n",
    "        path, date = os.path.split(path)\n",
    "        path, location = os.path.split(path)\n",
    "        image_id = location.replace(' ', '_') + '-' + date + '-' + im.replace('.jpeg','')\n",
    "    return image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeVariables(config_dict):\n",
    "    ini_section = getSectionToUse(config_dict)\n",
    "    # Initialise of output<dict> with items in reference.json\n",
    "    F_ref = open(config_dict[ini_section]['reference_file'],'r')  # TODO: add error checks\n",
    "    text_ = F_ref.read()\n",
    "    json_ref = json.loads(text_)\n",
    "    jsonOutput = {'categories': json_ref['categories'], \\\n",
    "                 'annotations': [], \\\n",
    "                 'images': json_ref['images'], \\\n",
    "                 'licenses': json_ref['licenses']}\n",
    "    F_ref.close()\n",
    "    \n",
    "    if not config_dict.has_option(ini_section, 'obj_of_interest'):\n",
    "        raise ValueError('Object of interest not found in env.ini')\n",
    "    \n",
    "    if not config_dict.has_option(ini_section, 'im_dir'):\n",
    "        raise ValueError('Image directory not found in env.ini')\n",
    "        \n",
    "    if not config_dict.has_option(ini_section, 'output_file'):\n",
    "        raise ValueError('Output_file path not found in env.ini')\n",
    "    \n",
    "    if not config_dict.has_option(ini_section, 'batch_size'):\n",
    "        raise ValueError('batch_size not found in env.ini')\n",
    "    \n",
    "    if not config_dict.has_option(ini_section, 'threshold'):\n",
    "        raise ValueError('Min. size for object detection, threshold, not found in env.ini')\n",
    "        \n",
    "    if not config_dict.has_option(ini_section, 'ann_id_prefix'):\n",
    "        raise ValueError('Annotation id prefix, ann_id_prefix not found in env.ini')\n",
    "    return jsonOutput, config_dict[ini_section]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "\n",
    "# INITIALISATION OF VARIABLES\n",
    "jsonOutput, config_ = initializeVariables(config_dict)  # use config with underscore to prevent conflict with pyco's config\n",
    "OBJECTS_OF_INTEREST_ls = config_['obj_of_interest']\n",
    "IM_DIR = config_['im_dir']\n",
    "output_file = config_['output_file']\n",
    "BATCH_SIZE = int(config_['batch_size'])\n",
    "THRESHOLD = float(config_['threshold'])\n",
    "ANN_ID_PREFIX = config_['ann_id_prefix']\n",
    "OBJECTS_OF_INTEREST_ls = [ int(x) for x in OBJECTS_OF_INTEREST_ls.replace('[','').replace(']','').split(',')]\n",
    "\n",
    "'BUS' in ', '.join([items['id'] for items in jsonOutput['categories']]).split(', ')\n",
    "ann_json_list = []\n",
    "done_list = []  # TODO: get done list\n",
    "global_counter = 1\n",
    "other_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     20\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 20\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                93\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(RCNN_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(RCNN_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "\n",
    "class InferenceConfig(coco.CocoConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = BATCH_SIZE\n",
    "\n",
    "inf_config = InferenceConfig()\n",
    "inf_config.display()\n",
    "\n",
    "# Create model object in inference mode.\n",
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=inf_config)\n",
    "\n",
    "# Load weights trained on MS-COCO\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True)\n",
    "\n",
    "# COCO Class names\n",
    "# Index of the class in the list is its ID. For example, to get ID of\n",
    "# the teddy bear class, use: class_names.index('teddy bear')\n",
    "# class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "#                'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "#                'fire hydrant', 'stop sign']\n",
    "\n",
    "# OVERRIDES MASK_RCNN DEFAULTS\n",
    "class_names = ['BG', 'person', 'bicycle', 'SEDAN', 'motorcycle', 'airplane',\n",
    "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "               'fire hydrant', 'stop sign']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bicycle\n",
      "train\n",
      "traffic light\n",
      "stop sign\n",
      "Removing bicycle from objects-of-interest list as it is not present in the category list of reference.json\n",
      "Removing train from objects-of-interest list as it is not present in the category list of reference.json\n",
      "Removing traffic light from objects-of-interest list as it is not present in the category list of reference.json\n",
      "Removing stop sign from objects-of-interest list as it is not present in the category list of reference.json\n"
     ]
    }
   ],
   "source": [
    "# REMOVES OBJECTS THAT ARE OF INTEREST BUT ARE NOT IN REFERENCE CATEGORY LIST\n",
    "categories_list = ', '.join([items['id'] for items in jsonOutput['categories']]).lower().split(', ')\n",
    "ref_indices_to_be_removed = []\n",
    "for obj_ref_idx in OBJECTS_OF_INTEREST_ls:\n",
    "    if not class_names[obj_ref_idx].lower() in categories_list:\n",
    "        ref_indices_to_be_removed.append(obj_ref_idx)\n",
    "        print(class_names[obj_ref_idx])\n",
    "for i in ref_indices_to_be_removed:\n",
    "    print('Removing ' + class_names[i] + ' from objects-of-interest list as it is not present in the category list of reference.json')\n",
    "    OBJECTS_OF_INTEREST_ls.remove(i)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36 images.\n",
      "20 image(s) done. 16 more to go. Hang in there!\n",
      "36 image(s) done. 0 more to go. Hang in there!\n",
      "641.5956346988678\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# MAIN\n",
    "# TODO track done images and images with objects not of interest\n",
    "list_of_image_paths = []\n",
    "for path, subdirs, files in os.walk(IM_DIR):\n",
    "    for file in files:\n",
    "        if file.endswith('.jpeg'):\n",
    "            list_of_image_paths.append(os.path.join(path, file))\n",
    "for path, subdirs, files in os.walk(IM_DIR):\n",
    "    for file in files:\n",
    "        if file.endswith('.jpeg'):\n",
    "            list_of_image_paths.append(os.path.join(path, file))\n",
    "\n",
    "print('Found ' + str(len(list_of_image_paths)) + ' images.')\n",
    "im_generator = enumerate(list_of_image_paths)\n",
    "global_counter = 0\n",
    "end_of_list = False\n",
    "start = time.time() \n",
    "if (len(list_of_image_paths)==0):\n",
    "    print('No images was found in ')\n",
    "\n",
    "while not end_of_list:\n",
    "    image_array = []\n",
    "    image_sz_array = []\n",
    "    image_path_array = []\n",
    "    for i in range(BATCH_SIZE):\n",
    "        try: im_counter, nxt_im_path = im_generator.__next__()\n",
    "        except StopIteration: end_of_list = True; break\n",
    "        image = skimage.io.imread(nxt_im_path)\n",
    "        image_array.append(image)\n",
    "        image_sz_array.append(image.shape)  # height, width, _ \n",
    "        image_path_array.append(nxt_im_path)\n",
    "\n",
    "    if len(image_array) == BATCH_SIZE:\n",
    "        test_results = model.detect(image_array, verbose=0)\n",
    "    else:\n",
    "        # initialise a model with the corresponding BATCH_SIZE\n",
    "        class InferenceConfig(coco.CocoConfig):\n",
    "            # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "            GPU_COUNT = 1\n",
    "            IMAGES_PER_GPU = len(image_array)  # New BATCH_SIZE\n",
    "\n",
    "        config = InferenceConfig()\n",
    "        # Create model object in inference mode.\n",
    "        model_ = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "        # Load weights trained on MS-COCO\n",
    "        model_.load_weights(COCO_MODEL_PATH, by_name=True)\n",
    "        test_results = model_.detect(image_array, verbose=0)\n",
    "\n",
    "    for ii in range(len(test_results)):\n",
    "        r = test_results[ii]\n",
    "        image_id = getImageIdfrmPath(image_path_array[ii])\n",
    "        height, width, _ = image_sz_array[ii]\n",
    "        for idx, roi in enumerate(r['rois']):\n",
    "            if len(OBJECTS_OF_INTEREST_ls) != 0 and r['class_ids'][idx] not in OBJECTS_OF_INTEREST_ls:\n",
    "                other_list.append({'category_id': idx, \"image_id\": image_id})\n",
    "                continue\n",
    "            y1, x1, y2, x2 = roi\n",
    "            aoi = r['masks'][y1:y2, x1:x2,idx]\n",
    "            input = image_array[ii][y1:y2, x1:x2]\n",
    "            colour, _ = detectColour(input, aoi)\n",
    "\n",
    "            bbox = [float(x1)/width, float(y1)/height, float(x2-x1)/width, float(y2-y1)/height]  # Normalise for annotation tool\n",
    "            if ((bbox[2]<THRESHOLD) or (bbox[3]<THRESHOLD)):\n",
    "                continue\n",
    "            cat_id = class_names[r['class_ids'][idx]].upper()\n",
    "\n",
    "            if cat_id != 'MOTORCYCLE':\n",
    "                ann = {\"id\" : ANN_ID_PREFIX+str(global_counter), \"image_id\": image_id, 'category_id': cat_id +\", \"+colour, 'bbox': bbox}\n",
    "            else:\n",
    "                ann = {\"id\" : ANN_ID_PREFIX+str(global_counter), \"image_id\": image_id, 'category_id': cat_id, 'bbox': bbox}\n",
    "\n",
    "            global_counter+=1\n",
    "            ann_json_list.append(ann)\n",
    "        if len(r['rois'])==0:\n",
    "            print('Nothing detected in image with id: '+ image_id)\n",
    "    \n",
    "    if (im_counter != 0 & ((im_counter % (5*BATCH_SIZE))==0)):\n",
    "        print(str(im_counter+1) + ' image(s) done. ' + str(len(list_of_image_paths)-im_counter-1) + ' more to go. Hang in there!')\n",
    "    \n",
    "\n",
    "end = time.time()\n",
    "print(end - start)\n",
    " \n",
    "if len(ann_json_list)==0:\n",
    "    print('Nothing detected.')\n",
    "else:\n",
    "    jsonOutput['annotations'] = ann_json_list\n",
    "    File = open(output_file,'w')\n",
    "    File.write(json.dumps(jsonOutput))\n",
    "    File.close()\n",
    "\n",
    "\n",
    "with open(output_file.replace('.json','_done_list.txt'), 'w') as f:\n",
    "    for item in list_of_image_paths:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "    f.close()\n",
    "\n",
    "if (len(other_list) != 0):\n",
    "    File = open(output_file.replace('.json','_strange_list.json'),'w')\n",
    "    File.write(json.dumps({'strange objects': other_list}))\n",
    "    File.close()\n",
    "    \n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (shapEnv)",
   "language": "python",
   "name": "shapenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
